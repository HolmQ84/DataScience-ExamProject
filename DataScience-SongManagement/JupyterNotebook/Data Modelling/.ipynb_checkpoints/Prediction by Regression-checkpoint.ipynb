{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18129628",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/cleanedDataset.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14556/3171644148.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# Load the data  import pandas as pd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../data/cleanedDataset.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \"\"\"\n\u001b[1;32m--> 222\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/cleanedDataset.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Load the data  import pandas as pd \n",
    "df = pd.read_csv(\"../data/cleanedDataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27ca696",
   "metadata": {},
   "source": [
    "## Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b59846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d7ccd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c528047",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549af0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there are any Null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81764e5b",
   "metadata": {},
   "source": [
    "## Plotting a couple of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddffc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,7))\n",
    "fig.add_subplot(2,1,1)\n",
    "sns.distplot(df['rank'])\n",
    "fig.add_subplot(2,1,2)\n",
    "sns.boxplot(df['streams'])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d562e5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 2:3].values # Rank\n",
    "y = df.iloc[:, 7].values # Streams\n",
    "\n",
    "plt.scatter(X, y)\n",
    "plt.title(\"Strams vs Rank\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9394224d",
   "metadata": {},
   "source": [
    "# Trying models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe9b5d7",
   "metadata": {},
   "source": [
    "Well. Its clearly not linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7e5c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Selection \n",
    "#X = df.iloc[:, 2:3].values # Rank\n",
    "singleArtistDF =df.loc[df['artist'] == \"Ed Sheeran\"]\n",
    "\n",
    "y = singleArtistDF.iloc[:, 7].values  # Rank\n",
    "X = singleArtistDF.iloc[:, 2:3].values # Streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c84c01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(2)\n",
    "X_poly = poly.fit_transform(X)\n",
    " \n",
    "poly.fit(X_poly, y)\n",
    "lin2 = LinearRegression()\n",
    "lin2.fit(X_poly, y)\n",
    "\n",
    "# Visualising the Polynomial Regression results\n",
    "plt.scatter(X, y, color = 'blue')\n",
    " \n",
    "plt.plot(X, lin2.predict(poly.fit_transform(X)), color = 'red')\n",
    "plt.title('Polynomial Regression')\n",
    "plt.xlabel('Rank')\n",
    "plt.ylabel('Streams')\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7c59e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lin2.predict(X_poly)\n",
    "print(r2_score(y, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1179cc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a exponential regression model\n",
    "\n",
    "ekspo_fit = np.polyfit(singleArtistDF['streams'], np.log(singleArtistDF['rank']), 1)\n",
    "\n",
    "y_predicted = np.exp(ekspo_fit[1]) * np.exp(ekspo_fit[0]*singleArtistDF['streams'])\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(singleArtistDF['streams'], singleArtistDF['rank'], \"o\")\n",
    "plt.plot(singleArtistDF['streams'], y_predicted)\n",
    "plt.xlabel('streams')\n",
    "plt.ylabel('rank')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625002ce",
   "metadata": {},
   "source": [
    "## Number of songs in a specifc year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c36455",
   "metadata": {},
   "outputs": [],
   "source": [
    "singleArtistDF = df.loc[df['artist'] == \"Ed Sheeran\"] # eddy BOII i choose youu!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594e9423",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataForEachMonthOfYear = []\n",
    "yearAndMonth = []\n",
    "formattedDateForGraph = []\n",
    "\n",
    "year = 2017\n",
    "month = 1\n",
    "\n",
    "searchString = \"\"\n",
    "\n",
    "for i in range(60):\n",
    "    \n",
    "    if (i == 11 or i == 22 or i == 33 or i == 44 or i == 55): \n",
    "        searchString = str(year) + '-' + str(month)\n",
    "        dataForEachMonthOfYear.append(singleArtistDF.loc[singleArtistDF['date'].str.contains(pat = searchString)])\n",
    "        yearAndMonth.append(str(year) + '.' + str(month))\n",
    "        #print(searchString)\n",
    "        year = year + 1 #Changes the year\n",
    "        month = 1 \n",
    "    if month < 10:    \n",
    "        searchString = str(year) + '-' + '0' +str(month)\n",
    "    else:\n",
    "        searchString = str(year) + '-' + str(month)\n",
    "    \n",
    "    #print(searchString)\n",
    "    dataForEachMonthOfYear.append(singleArtistDF.loc[singleArtistDF['date'].str.contains(pat = searchString)])\n",
    "    yearAndMonth.append(str(year) + '.' + str(month))\n",
    "    \n",
    "    month = month + 1\n",
    "    i + 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a604478a",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearAndMonth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dd23bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection \n",
    "#X = df.iloc[:, 2:3].values # Rank\n",
    "singleArtistDF = df.loc[df['artist'] == \"Ed Sheeran\"]\n",
    "\n",
    "#y = [allSongsFrom2017['title'].count(), allSongsFrom2018['title'].count(), allSongsFrom2019['title'].count(), allSongsFrom2020['title'].count(), allSongsFrom2021['title'].count()]  # Rank\n",
    "#X = [2017, 2018, 2019, 2020, 2021] # Streams\n",
    "y = dataForEachMonthOfYear\n",
    "X = yearAndMonth \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e43102",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = [float(i) for i in X]\n",
    "y[1]['title'].count()\n",
    "newy = []\n",
    "\n",
    "for i in range(len(y)):\n",
    "    newy.append(y[i]['title'].count())\n",
    "\n",
    "print(newy)    \n",
    "plt.scatter(newy, X)\n",
    "plt.title(\"Numbers of published songs pr year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba0c819",
   "metadata": {},
   "source": [
    "## Polynomral with data pr year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1341fec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching all songs from specific year from eddy Boiiii\n",
    "allSongsFrom2017 =  singleArtistDF.loc[singleArtistDF['date'].str.contains(pat = '2017')]\n",
    "allSongsFrom2018 =  singleArtistDF.loc[singleArtistDF['date'].str.contains(pat = '2018')]\n",
    "allSongsFrom2019 =  singleArtistDF.loc[singleArtistDF['date'].str.contains(pat = '2019')]\n",
    "allSongsFrom2020 =  singleArtistDF.loc[singleArtistDF['date'].str.contains(pat = '2020')]\n",
    "allSongsFrom2021 =  singleArtistDF.loc[singleArtistDF['date'].str.contains(pat = '2021')]\n",
    "\n",
    "allSongsFrom2017['title'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c42e6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [2017, 2018, 2019, 2020, 2021]\n",
    "y = [allSongsFrom2017['title'].count(), allSongsFrom2018['title'].count(), allSongsFrom2019['title'].count(), allSongsFrom2020['title'].count(), allSongsFrom2021['title'].count()]\n",
    "\n",
    "X = np.array(X) # Reshaping 1d array to 2d\n",
    "y = np.array(y) # Reshaping 1d array to 2d\n",
    "X = X.reshape(-1, 1)\n",
    "y = y.reshape(-1, 1)\n",
    "\n",
    "\n",
    "\n",
    "poly = PolynomialFeatures(4)\n",
    "X_poly = poly.fit_transform(X)\n",
    " \n",
    "poly.fit(X_poly, y)\n",
    "lin2 = LinearRegression()\n",
    "lin2.fit(X_poly, y)\n",
    "\n",
    "# Visualising the Polynomial Regression results\n",
    "plt.scatter(X, y, color = 'blue')\n",
    " \n",
    "plt.plot(X, lin2.predict(poly.fit_transform(X)), color = 'red')\n",
    "plt.title('Polynomial Regression')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('nr of songs published')\n",
    " \n",
    "plt.show()\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(mean_squared_error(y, y_pred))\n",
    "\n",
    "y_pred = lin2.predict(X_poly)\n",
    "print(r2_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0efa7d",
   "metadata": {},
   "source": [
    "## Using the predictive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc44fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearToPredict = 2017\n",
    "\n",
    "poly_reg = PolynomialFeatures(degree=4)\n",
    "temp = lin2.predict(poly_reg.fit_transform([[yearToPredict]]))\n",
    "\n",
    "\"{:.0f}\".format(float(temp))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3951b915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(lin2, '../5 - Communicate results/regressionPredictor.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9ba42e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41f0e464",
   "metadata": {},
   "source": [
    "## converting the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f88562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the model object\n",
    "model = PolynomialFeatures(degree=4)\n",
    "\n",
    "# fitting model with X_train - area, y_train - price\n",
    "model.fit(X, y)\n",
    "\n",
    "model.predict([[5000]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6643a39",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d11029",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [allSongsFrom2017['title'].count(), allSongsFrom2018['title'].count(), allSongsFrom2019['title'].count(), allSongsFrom2020['title'].count(), allSongsFrom2021['title'].count()]\n",
    "y = [2017, 2018, 2019, 2020, 2021]\n",
    "\n",
    "X = np.array(X) # Reshaping 1d array to 2d\n",
    "y = np.array(y) # Reshaping 1d array to 2d\n",
    "X = X.reshape(-1, 1)\n",
    "y = y.reshape(-1, 1)\n",
    "\n",
    "# Create a linear regression model.\n",
    "regressor = LinearRegression()\n",
    "\n",
    "#Train the model using the dataset.\n",
    "regressor.fit(X, y)\n",
    "\n",
    "values_predicted = regressor.predict(X)\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.scatter(X, y,)\n",
    "plt.plot(X, values_predicted, color='orange')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Nr of songs published')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
